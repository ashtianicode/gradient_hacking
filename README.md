# gradient_hacking
does the model preserve its goal under the pressure of optimization (fine-turning)
